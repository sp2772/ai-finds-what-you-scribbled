{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc454034-66b6-4317-b915-e2d5b11bccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 22:47:37.900424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf05d4a-080e-4641-8096-d874866e1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras import layers, models,optimizers, callbacks\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63064d7f-349a-4079-b9d7-cee82f571d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2181d42f-df08-496a-ab31-f5fe4be2265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONFIG ====\n",
    "IMG_SIZE = 160\n",
    "DATA_DIR = \"/mnt/d/MyEverything/PythonProjects/Recent_projects/cnn_analysis/Hand_Drawing/quickdraw_images\"  # <- Replace this with your dataset path\n",
    "PARTIAL_STEPS = [0.5, 1.0]\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "CLASSES_LIMIT = 50\n",
    "MAX_SAMPLES_PER_CLASS = 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c69010e-2a1d-4834-a48f-d9a317362781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths_and_labels(base_dir):\n",
    "    classes = sorted(os.listdir(base_dir))\n",
    "    if CLASSES_LIMIT:\n",
    "        classes = classes[:CLASSES_LIMIT]\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "    for cls in classes:\n",
    "        class_path = os.path.join(base_dir, cls)\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.endswith('.png')]\n",
    "        all_paths.extend(images)\n",
    "        all_labels.extend([cls] * len(images))\n",
    "    return all_paths, all_labels, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edb84a7-e7ab-465c-93af-61fbeae94f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochSampler:\n",
    "    def __init__(self, all_filepaths, all_labels, class_to_idx, max_per_class=10000):\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.max_per_class = max_per_class\n",
    "        self.class_map = defaultdict(list)\n",
    "        for path, label in zip(all_filepaths, all_labels):\n",
    "            self.class_map[label].append(path)\n",
    "\n",
    "    def sample_epoch_data(self):\n",
    "        sampled_paths, sampled_labels = [], []\n",
    "        for cls, paths in self.class_map.items():\n",
    "            selected = random.sample(paths, min(self.max_per_class, len(paths)))\n",
    "            sampled_paths.extend(selected)\n",
    "            sampled_labels.extend([cls] * len(selected))\n",
    "        return sampled_paths, sampled_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93778ec8-b7af-49c2-9a46-0733ef25ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, filepaths, labels, batch_size, class_to_idx, steps=[1.0], shuffle=True):\n",
    "        self.filepaths = np.array(filepaths)\n",
    "        self.labels = np.array(labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.steps = steps\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.filepaths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inds = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x = self.filepaths[inds]\n",
    "        batch_y = [self.class_to_idx[self.labels[i]] for i in inds]\n",
    "        X = []\n",
    "        \n",
    "        for path in batch_x:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img is None:\n",
    "                img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
    "            else:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # ✅ Ensure correct size\n",
    "            \n",
    "            # Create partial mask\n",
    "            mask = np.ones_like(img, dtype=np.uint8) * 255\n",
    "            step_ratio = random.choice(self.steps)\n",
    "            height = int(IMG_SIZE * step_ratio)\n",
    "            mask[height:, :] = 255\n",
    "            \n",
    "            img = cv2.bitwise_and(img, mask)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)  # Shape: (IMG_SIZE, IMG_SIZE, 1)\n",
    "            X.append(img)\n",
    "    \n",
    "        X = np.array(X)  # Shape: (batch_size, IMG_SIZE, IMG_SIZE, 1)\n",
    "        y = tf.keras.utils.to_categorical(batch_y, num_classes=len(self.class_to_idx))\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c54aefc-6b53-4782-858f-14744e11877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- CNN MODEL -------------------\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85dea7f-6d66-4858-95ad-f3e6e44c8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41472</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,617,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,850</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m, \u001b[38;5;34m158\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m, \u001b[38;5;34m79\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m77\u001b[0m, \u001b[38;5;34m77\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41472\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m10,617,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m12,850\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,722,610</span> (40.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,722,610\u001b[0m (40.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,722,610</span> (40.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,722,610\u001b[0m (40.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------- MAIN -------------------\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "all_paths, all_labels, class_to_idx = get_filepaths_and_labels(DATA_DIR)\n",
    "sampler = EpochSampler(all_paths, all_labels, class_to_idx, MAX_SAMPLES_PER_CLASS)\n",
    "\n",
    "model = build_cnn_model((IMG_SIZE, IMG_SIZE, 1), len(class_to_idx))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa81c7-3f25-4288-acf0-7e4799256740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Windows/system32/tf_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748872393.243726    4173 service.cc:148] XLA service 0x7fbda800ec40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748872393.248281    4173 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-06-02 22:53:13.458427: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1748872393.814740    4173 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-06-02 22:53:19.942682: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng40{k2=5,k13=1,k14=3} for conv (f16[32,38,38,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,36,36,128]{3,2,1,0}, f16[128,3,3,64]{3,2,1,0}), window={size=3x3}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-06-02 22:53:19.952227: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.972716259s\n",
      "Trying algorithm eng40{k2=5,k13=1,k14=3} for conv (f16[32,38,38,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,36,36,128]{3,2,1,0}, f16[128,3,3,64]{3,2,1,0}), window={size=3x3}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1748872404.470051    4173 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1373/5766\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:51\u001b[0m 476ms/step - accuracy: 0.2244 - loss: 3.1217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2301/5766\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27:30\u001b[0m 476ms/step - accuracy: 0.3029 - loss: 2.7828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4203/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m12:11\u001b[0m 468ms/step - accuracy: 0.3898 - loss: 2.4150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5766/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2977s\u001b[0m 514ms/step - accuracy: 0.4317 - loss: 2.2410 - val_accuracy: 0.7100 - val_loss: 1.1376\n",
      "\n",
      "[INFO] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Windows/system32/tf_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3721/5766\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m20:33\u001b[0m 603ms/step - accuracy: 0.6775 - loss: 1.2359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4936/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8:04\u001b[0m 584ms/step - accuracy: 0.6789 - loss: 1.2304 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5766/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step - accuracy: 0.6799 - loss: 1.2263  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5766/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3607s\u001b[0m 626ms/step - accuracy: 0.6799 - loss: 1.2263 - val_accuracy: 0.7437 - val_loss: 0.9868\n",
      "\n",
      "[INFO] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Windows/system32/tf_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 833/5766\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39:06\u001b[0m 476ms/step - accuracy: 0.7070 - loss: 1.1257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2447/5766\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m45:16\u001b[0m 818ms/step - accuracy: 0.7094 - loss: 1.1098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5766/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867ms/step - accuracy: 0.7121 - loss: 1.0995   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5766/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5802s\u001b[0m 1s/step - accuracy: 0.7121 - loss: 1.0995 - val_accuracy: 0.7621 - val_loss: 0.8938\n",
      "\n",
      "[INFO] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Windows/system32/tf_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 417/5766\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:28\u001b[0m 1s/step - accuracy: 0.7292 - loss: 1.0157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4599/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m17:08\u001b[0m 881ms/step - accuracy: 0.7344 - loss: 1.0120   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4906/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m12:33\u001b[0m 876ms/step - accuracy: 0.7344 - loss: 1.0119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5766/5766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5442s\u001b[0m 944ms/step - accuracy: 0.7345 - loss: 1.0115 - val_accuracy: 0.7784 - val_loss: 0.8479\n",
      "\n",
      "[INFO] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Windows/system32/tf_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 102/5766\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:35\u001b[0m 748ms/step - accuracy: 0.7528 - loss: 0.9232"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n[INFO] Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    epoch_paths, epoch_labels = sampler.sample_epoch_data()\n",
    "    tr_paths, val_paths, tr_labels, val_labels = train_test_split(\n",
    "        epoch_paths, epoch_labels, test_size=0.1, stratify=epoch_labels, random_state=random.randint(1, 9999))\n",
    "    train_gen = SketchDataGenerator(tr_paths, tr_labels, BATCH_SIZE, class_to_idx, PARTIAL_STEPS)\n",
    "    val_gen = SketchDataGenerator(val_paths, val_labels, BATCH_SIZE, class_to_idx, [1.0], shuffle=False)\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2a6b9-b8bd-4766-b11a-a6c00a4455d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_more_epochs(model, all_paths, all_labels, class_to_idx, epochs, batch_size=64, max_samples_per_class=10000, partial_steps=[0.25, 0.5, 0.75, 1.0]):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import random\n",
    "\n",
    "    sampler = EpochSampler(all_paths, all_labels, class_to_idx, max_samples_per_class)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[INFO] Additional Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_paths, epoch_labels = sampler.sample_epoch_data()\n",
    "        tr_paths, val_paths, tr_labels, val_labels = train_test_split(\n",
    "            epoch_paths, epoch_labels, test_size=0.1, stratify=epoch_labels, random_state=random.randint(1, 9999)\n",
    "        )\n",
    "        train_gen = SketchDataGenerator(tr_paths, tr_labels, batch_size, class_to_idx, partial_steps)\n",
    "        val_gen = SketchDataGenerator(val_paths, val_labels, batch_size, class_to_idx, [1.0], shuffle=False)\n",
    "        model.fit(train_gen, validation_data=val_gen, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fff800-1dcc-4f47-a951-1b7390f06fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_more_epochs(model, all_paths, all_labels, class_to_idx, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a9f01-d048-4650-9232-8db7921c7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[INFO] Measuring inference time...\")\n",
    "test_img_path = random.choice(all_paths)\n",
    "test_img = cv2.imread(test_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "test_img = cv2.resize(test_img, (IMG_SIZE, IMG_SIZE))\n",
    "test_img = test_img.astype(np.float32) / 255.0\n",
    "test_img = np.expand_dims(test_img, axis=-1)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "\n",
    "start_time = time.time()\n",
    "_ = model.predict(test_img)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Inference time for one image: {end_time - start_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
